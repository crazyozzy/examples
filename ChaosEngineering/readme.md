# Chaos Engineering
** Chaos Engineering ** – относительно новое, однако уже широко востребованное направление обеспечения устойчивости систем уже на этапе разработки ПО.
Несмотря на то, что Chaos Engineering (далее — CE) все ещё остаётся относительно новым направлением в разработке программного обеспечения, революция в подходе к  комплексному тестированию уже свершилась.
Тысячи компаний разных размеров и разного уровня развития используют этот метод в качестве основного инструмента тестирования и контроля, чтобы сделать свои продукты и услуги более безопасными и надёжными.



** Chaos Engineering ** – это дисциплина экспериментов с распределённой системой, призванных подтвердить способность системы противостоять турбулентным условиям рабочей среды.
Это особая форма экспериментов, которая стоит отдельно от тестирования.
Основа Chaos Engineering – что-то специально сломать, имитируя события из реальной жизни, чтобы посмотреть, что произойдёт, и как ваши системы с этим справятся.

Суть Chaos Engineering в том, что любая, даже самая глупая гипотеза моделирования «реальных сбоев», должна пройти эксперимент в рамках вашей системы IT, особенно это касается сетей.

Цель Chaos Engineering, в первую очередь, заключается в укреплении доверия к системе.
«Турбулентные условия рабочей среды», означают, что речь идёт не о создании хаоса.
Chaos Engineering – это приём, который делает видимым хаос, изначально присущей системе или среде её функционирования.
Хаос изучается через эксперименты, и поэтому Chaos Engineering больше похож на науку, чем на технологию.

# Traffic Control
Позволяет организовывать потери, задержки при приёме и отправке сетевых пакетов, изменение пакетов и многое другое. Входит в состав пакета iproute2.

Используется для настройки системы контроля трафика, который состоит из:
* Ограничения исходящего трафика (shaping)
* Когда трафик сформирован, его полоса пропускания начинает контролироваться. Ограничение может дать больше, чем уменьшение полосы пропускания – оно также используется для сглаживания пиков для более прогнозируемого поведения сети
* Планирования (scheduling)
* Планирование передачи пакетов позволяет увеличить интерактивность исходящего трафика при гарантировании полосы пропускания для передачи данных большого объёма. Такое упорядочение также называется приоритизацией и применяется для исходящего трафика
* Ограничения входящего трафика (policing)
* Механизм, с помощью которого можно ограничить количество пакетов или байт в потоке входящего трафика, соответствующих определённой классификации
* Отбрасывания (dropping)
* Трафик, превышающий установленную полосу пропускания, может быть отброшен как для входящего, так и исходящего трафика.

Обработка трафика контролируется тремя типами объектов: очередями (qdiscs), классами и фильтрами.

Каждый из интерфейсов может иметь входящие (ingress) и исходящие (egress) дисциплины (точки), к которым подключаются конструкции управления трафиком для управления исходящим (egress) и входящим (ingress) трафиком.
Каждый интерфейс имеет эти две точки.

Основной и наиболее используемой точкой для исходящего трафика является egress, которая часто и называется "корневой дисциплиной обработки очереди" (root qdisc).
Она может содержать любую настоящую дисциплину обработки очереди (qdisc).
В подавляющем большинстве документации используется термин "корневая дисциплина" и ее потомки. Весь исходящий трафик интерфейса проходит через корневую дисциплину.

Входящий трафик, в свою очередь, проходит через входящую дисциплину (ingress qdisc).
Из-за ограниченных возможностей, у неё нельзя создавать классы, можно лишь подключить к ней фильтр.
На практике, входящая дисциплина представляет собой объект, к которому подключается ограничитель для регулирования скорости входящего трафика на интерфейсе.

В большинстве экспериментов производится воздействие на исходящий трафик.
Но в некоторых случаях может потребоваться произвести воздействие на входящий трафик (например, ограничение входящего трафика или эмуляция уменьшения полосы пропускания).

## Примеры воздействия на исходящий трафик
Используем qdisc для эмуляции нестабильности сети (будем использовать classless qdisc netem).

**Network delay**
Задержка передачи пакетов на сетевом интерфейсе ethX до 200 мс
`tc qdisc add dev ethX root netem delay 200ms`

**Network loss**
Потери 30% пакетов на сетевом интерфейсе ethX
`tc qdisc add dev ethX root netem loss 30%`

**Network corrupt**
Повреждение 30% пакетов на сетевом интерфейсе ethX
`tc qdisc add dev ethX root netem corrupt 30%`

**Network duplicate**
Дублирование 20% пакетов на сетевом интерфейсе ethX
`tc qdisc add dev ethX root netem duplicate 20%`

**Network reorder**
Первый способ – разрыв. Использует фиксированную последовательность и переупорядочивает каждый N-й пакет.
Каждый 5-й (10-й, 15-й, ...) пакет отправляется немедленно, а каждый другой пакет задерживается на 10 мс.
Это предсказуемо и полезно для тестирования базового протокола, такого как повторная сборка.
`tc qdisc add dev eth0 root netem gap 5 delay 10ms`

Второй способ – изменить порядок, переупорядочивание.
Больше похоже на реальную жизнь.
Это приводит к неправильному порядку определённого процента пакетов.
В этом примере 25% пакетов (с корреляцией 50%) будут отправлены немедленно, остальные будут задержаны на 10 мс.
`tc qdisc add dev eth0 root netem delay 10ms reorder 25% 50%`

Вернуть параметры egress по умолчанию
`tc qdisc del dev ethX root`

## Примеры воздействия на входящий трафик
Воздействие на входящий трафик никак не затрагивает и не применяется к исходящему трафику и позволяет устанавливать tc-фильтры для входящих пакетов, вне зависимости от того, предназначены ли они для данного хоста или должны быть перенаправлены дальше.

**Ограничение входящего icmp-трафика до 2 Кбит.**
При превышении предела пакеты отбросить:
`tc filter add dev ethX parent ffff: protocol ip prio 20 u 32 match ip protocol 1 0xff police rate 2kbit buffer 10k drop flowid :1`

**Ограничение размера пакетов** (т.е. все пакеты, имеющие размер более чем 84 байта, будут сброшены):
`tc filter add dev ethX parent ffff: protocol ip prio 20 u 32 match tos 0 0 police mtu 84 drop flowid :1`

**Ситуация, когда входящий канал стал иметь пропускную способность 1Кбит/сек:**
`tc filter add dev ethX parent ffff: protocol ip prio 50 handle 1 fw police rate 1kbit burst 40 mtu 9k drop flowid :1`

Расширенный пример.
Допустим, необходимо ограничить скорость входящего трафика протокола tcp c ip-адреса 192.168.10.3 на адрес 192.168.10.5
Можно сделать это следующим образом:
    добавляем дисциплину для входящего трафика
    `tc qdisc add dev ethX ingress`

    добавляем фильтр с полисером
        протокол tcp
        адрес источника 192.168.10.3/32
        адрес назначения 192.168.10.5/32

`tc filter add dev ethX parent ffff: pref 10 protocol ip handle ::1 u32 match ip protocol 6 0xff match ip src 192.168.10.3/32 match ip dst 192.168.10.5/32 action police rate 2Mbit burst 200K gact drop`

Самый большой интерес представляют следующие параметры:
**action police** – указывает на то, что подпадающий под фильтр трафик будет обрабатываться полисером. Далее идут параметры полисера.
**rate 2Mbit burst 200K** – задаёт полосу пропускания в 2 мегабита в секунду.
«burst 200K» – это один из параметров, нужный для правильной работы полисера.
Есть и другие параметры, но мы их не будем рассматривать.

**exceed-conform drop** определяет действие над пакетами, которые «переливаются через край ведра», в данном случае (action police) они отбрасываются.
Пакеты, которые влезают в полосу 2 мегабита, пропускаются.

Удаление ingress qdisc:
`tc qdisc del dev ethX ingress`

# Stress-ng
**stress-ng** – создание нагрузки на процессор (процессоры), оперативную память, подсистему ввода-вывода.

Применима в Chaos Engineering для эмуляции стрессовых условий работы тестируемых систем.

Используя stress-ng можно имитировать реальную рабочую нагрузку на тестируемые подсистемы для оценки их возможностей и контроля стабильности работы компьютера (процессора, виртуальной памяти и дисков).

Также выполнение стресс-тестов может быть полезно для наблюдения за изменениями производительности на разных выпусках операционной системы или её работы на разных типах оборудования.

Многофункциональная и гибкая утилита, одной из ключевых особенностей является наличие встроенных тестов.
Утилита абсолютно самодостаточна.

При выполнении тестов не производится обращение к сторонним приложениям и/или внешним ресурсам.

Можно задать количество процессов вызываемых для каждого типа стресс-теста, при отрицательном или нулевом значении их количество определяется возможностями процессора (автоматически).

Доступно семьдесят восемь специфичных для процессора стресс-тестов, в совокупности позволяющих наиболее реалистично задать нагрузку на процессор, используя целочисленные вычисления и вычисления с плавающей запятой, битовые вычисления, комплексные вычисления и пр.

Имеется более двадцати готовых стресс-тестов виртуальной памяти, имеющие конкретный метод тестирования.

stress-ng при запуске "тестов по умолчанию" выполняет все доступные для выбранной категории тесты (последовательно друг за другом).

Для контроля работы оборудования в режиме реального времени, при запуске стресс-теста, можно использовать набор консольных утилит sysstat (измерение и анализ производительности системы).

О возможностях stress-ng можно почитать по ссылкам:
[Stress-ng. Утилита нагрузочного тестирования аппаратного обеспечения](https://redos.red-soft.ru/base/manual/redos-manual/utilites/hardware-stress-test/stress-ng/)
[Стресс-тестирование систем в Linux. Утилита stress-ng](https://itproffi.ru/stress-testirovanie-sistem-v-linux-utilita-stress-ng/)
[Стресс-тестирование серверов с помощью stress-ng](https://highload.today/stress-testirovanie-serverov-s-pomoschyu-stress-ng/)
[stress-ng. Инструмент для стресс-тестов](https://highload.today/stress-testirovanie-serverov-s-pomoschyu-stress-ng/)
[Подробный мануал по stress-ng](https://manned.org/man/debian-bullseye/stress-ng.1)

## Тестирование процессора

В данном тесте задействованы 16 потоков для тестирования 16-ядерного процессора
`stress-ng --cpu 16 --cpu-method matrixprod --metrics --timeout 60`

В этом примере, используется 16 ядер процессора и останавливается после 900 000 операций.
`stress-ng --cpu 16 --cpu-ops 900000`

Запуск FFT теста на двух ядрах процессора, остановка после 5000 операций
`stress-ng --cpu 2 --cpu-method fft --cpu-ops 5000 --metrics-brief`

## Тестирование дисковой подсистемы (низкоуровневый тест ввода вывода)
`stress-ng --sequential 0 --class io --timeout 60s --metrics-brief`

Запуск пяти потоков чтения/записи для жёстких дисков, которые будут остановлены по завершении 100000 bogo-операций.
То есть стрессовая операция будет выполняться в пять потоков, количество циклов – 100 000 (это метрика bogo-ops – фиктивные операции в секунду).
`stress-ng --hdd 5 --hdd-ops 100 000`

Во время тестирования дисковой подсистемы, можно смотреть загрузку командой iostat. 

## Тестирование памяти

`stress-ng --sequential 0 --class memory --timeout 60s --metrics-brief`

Если необходимо провести комплексное стресс-тестирование, можно задействовать работу нескольких основных подсистем вместе одной командой.

Например, эта команда запустит тест для 4-х ядер CPU, тест виртуальной памяти с размещением в ней 1 Гб данных, а также 4 потока для тестирования операций ввода/вывода.
`stress-ng --cpu 4 --io 4 --vm 1 --vm-bytes 1G --timeout 60s --metrics-brief`

С помощью следующей команды можно запустить все имеющиеся в утилите тесты (после выполнения результат будет выведен в консоль):
`stress-ng --sequential 0 --timeout 60s --metrics-brief`

# Chaosblade
**ChaosBlade** – универсальный инструмент для проведения деструктивного тестирования, объединяющий в себе сразу несколько инструментов.

Используя chaosblade, можно осуществлять тесты с загрузкой процессора, памяти, подсистемы ввода/вывода.
Являясь обёрткой над tc (traffic control), chaosblade позволяет организовывать неполадки в сети, такие как потери, задержки, повреждения, дублирование и перестановка сетевых пакетов.
Также может применяться для реализации тестов для JVM приложений.

Тот факт, что chaosblade позволяет произвести такие разнообразные эксперименты, делает его крайне удобным, т. к. нет необходимости использовать несколько различных инструментов для тестирования и, соответственно, запоминать синтаксис каждого из них.

Инструмент Chaos Engineering, который следует экспериментальным принципам Chaos Engineering, предоставляет множество сценариев сбоев и помогает распределённым системам повысить отказоустойчивость и восстанавливаемость.

О chaosblade можно почитать по ссылке:
1. [chaosblade. Github, релизы](https://github.com/chaosblade-io/chaosblade)

## Утилизация CPU

Эксперименты, связанные с процессором, включают полную загрузку процессора.
Можно указывать количество ядер, конкретное ядро/ядра или процент от общей загрузки процессора.

Загрузка всех процессоров на XX % на 1 сервере в течение 300 секунд
**blade create cpu load --cpu-percent XX --timeout 300**

Для утилизации нескольких процессоров применяется параметр --cpu-count

Следующая команда загрузит YY процессоров на 1 сервере, на ХХ %, в течение 300 секунд
`blade create cpu load --cpu-count YY --cpu-percent XX --timeout 300`

Для указания конкретного ядра процессора применяется параметр --cpu-list
Следующая команда загрузит ядро 0 и ядро 3 на 1 сервере, на ХХ %, в течение 300 секунд
`blade create cpu load --cpu-list 0,3 --cpu-percent XX --timeout 300`

Следующая команда загрузит ядра с 1 по 3 на 1 сервере, на ХХ %, в течение 300 секунд
`blade create cpu load --cpu-list 1-3 --cpu-percent XX --timeout 300`

## Утилизация RAM

Рекомендуется указать процент занимаемой памяти!
Перед выполнением команды использовать команду top для просмотра информации об использовании памяти.
Даже если указан параметр --timeout, могут возникнуть ситуации, когда blade не может быть остановлен.
Это можно решить, перезапустив машину, или убить процесс chaos_burnmem!

Существует два типа памяти: ram и cache. Выбираются параметром --mode (ram|cache).
Режим --mode ram является предпочтительным, хотя, по-умолчанию (до версии 1.5.0 включительно), без указания --mode ram, используется режим --mode cache. При выборе --mode cache происходит монтирование tmpfs.
Режим --mode ram позволяет использовать ещё один параметр --rate, для указания скорости заполнения памяти, в Мб/с. 
Загрузка оперативной памяти на XX % на 1 сервере в течение 300 секунд

`blade create mem load --mode ram --mem-percent XX --timeout 300`

## Утилизация HDD I/O
Для реализации утилизации HDD I/O chaosblade использует утилиту dd (data definition).

Увеличить нагрузку ввода/вывода при чтении/записи можно, указав каталог, или изменить нагрузку ввода/вывода, отрегулировав размер блока чтения/записи.
Значение по умолчанию – 10Mб, а количество блоков фиксировано – 100.
Т. е. по умолчанию запись займёт 1000 Мб дискового пространства, а чтение 600 Мб дискового пространства.
Поскольку операция чтения сначала создаст файл фиксированного размера размером 600 Мб, ожидается, что в течение 3 секунд ввод/вывод записи увеличится при его создании.

**Загрузка вывода**
Чтение с диска с высокой загрузкой в течение 300 секунд
`blade create disk burn --read --path /dir --timeout 300`

**Загрузка ввода**
Запись на диск с высокой загрузкой в течение 300 секунд
`blade create disk burn --write --path /dir --timeout 300`

Чтение и запись дисков одновременно в течение 300 секунд
`blade create disk burn --read --write --path /dir --timeout 300`

В качестве временной директории, в параметре --path /dir, подставить директорию, к которой есть доступ для чтения и записи (например /tmp или /home/username).

## Network
Для влияния на сеть chaosblade использует утилиту tc (traffic control).
Следует обратить особое внимание на то, что не стоит забывать добавлять параметры --timeout и/или --exclude-port.
Первый предназначен для указания продолжительности выполнения (в секундах) и автоматического прекращения эксперимента, а второй для указания порта/портов, исключённых из эксперимента.
Если не указывать эти параметры, то при выборе слишком большого значения задержки можно потерять доступ и возможность управления!
Если эта проблема возникла, можно перезагрузить компьютер для восстановления.

Для указания конкретных локальных и удалённых портов применяются параметры --local-port XX и --remote-port XX соответственно.
Параметром --destination-ip можно выбрать конкретный IP-адрес назначения (удалённый хост).

**Задержки пакетов (delay)**
Создать задержку в одну секунду (1000 ms) на интерфейсе eth0, исключив порт 22 (ssh), продолжительность эксперимента – 300 секунд:
`blade create network delay --time 1000 --interface eth0 --exclude-port 22 --timeout 300`

Создать задержку в одну секунду на интерфейсе eth0 для трафика на удалённый хост 172.16.xx.xx и удалённый порт 80, продолжительность эксперимента 300 секунд:
`blade create network delay --time 1000 --interface eth0 --remote-port 80 --destination-ip 172.16.xx.xx --timeout 300`

**Потери пакетов (loss)**
Создание 15% потерь в сети на интерфейсе eth0, исключив порты 22 и 443, продолжительность эксперимента – 300 секунд:
`blade create network loss --percent 15 --interface eth0 --exclude-port 22,443 --timeout 300`

Создание 15 % потерь в сети на интерфейсе eth0, на удалённый хост 172.16.xx.xx и удалённый порт 80, продолжительность эксперимента 300 секунд:
`blade create network loss --percent 15 --interface eth0 --remote-port 80 --destination-ip 172.16.xx.xx --timeout 300`

**Повреждение пакетов (corrupt)**
Создание повреждения 15 % пакетов на интерфейсе eth0, на удалённый хост 172.16.xx.xx, продолжительность эксперимента – 300 секунд:
`blade create network corrupt --percent 15 --interface eth0 --destination-ip 172.16.xx.xx --timeout 300`

**Изменение порядка пакетов (reorder)**
Создание изменения порядка 25 % пакетов с корреляцией 30 (задаётся от 0 до 100), с размером последовательности 2 (только положительное число) и задержкой 300 мс, на интерфейсе eth0, на удалённый хост 172.16.xx.xx, продолжительность эксперимента – 300 секунд:
`blade create network reorder --percent 25 --correlation 30 --gap 2 --time 300 --interface eth0 --destination-ip 172.16.xx.xx --timeout 300`

**Дублирование пакетов (duplicate)**
Создание дублирования 20% пакетов на интерфейсе eth0, на удалённый хост 172.16.xx.xx, исключив порт 22, продолжительность эксперимента – 300 секунд:
`blade create network duplicate --percent 20 --interface eth0 --destination-ip 172.16.xx.xx --exclude-port 22 --timeout 300`

## Chaosblade-Operator
Инструмент внедрения экспериментов (Chaos-тестов) cloud-native приложений в среде Kubernetes или OpenShift.
Позволяет проводить широкий спектр экспериментов (CPU, RAM, HDD, NET, kill и т. д.).
Chaosblade-operator организует тесты в подах, используя chaosblade.

Инструмент chaosblade-operator разворачивается и настраивается в кластерах OpenShift централизованно и единоразово в каждом кластере при появлении такового.
Разворачивается в отдельный namespace проектной области chaostools и может быть только один на весь кластер.

Создаются SA (service account), RB (role binding) Администраторами проекта и по заявке на ИНФРу CRD.
Имя проекта различается в зависимости от кластера OpenShift.

Актуальная информация на странице Имеющиеся ресурсы.

Для каждой атаки делается свой, заранее настроенный конфигурационный файл (например, - chaosblade-cpu-load-pod-by-labels.yaml).

Пример запуска:
`oc process –f CloudAttack/attacks/chaosblade-cpu-load-pod-by-labels.yaml -p target_namespace=ci01234567-chaostools-server000002-idm -p target_labels=app=chaoskube -p max_target_count=1 -p cpu_load_percent=100 | oc create -f -`

Результат запуска:
`chaosblade.chaosblade.io/cpu-load-pod-by-labels-ci01234567-chaostools-server000002-idm created`

Завершение теста:
`oc delete blade cpu-load-pod-by-labels-ci01234567-chaostools-server000002-idm`

# Chaoskube
Инструмент хаос инжиниринга с открытым исходным кодом, который периодически убивает случайные поды в кластере Kubernetes/OpenShift.
Он помогает вам понять, как система отреагирует на отказ пода.
Например, можно задать в настройках «убивать под» в заданном пространстве имён каждые 10 минут.
Можно фильтровать целевые поды в chaoskube, используя пространства имён, метки, аннотации и т. д.

Разворачивается в целевой namespace тестируемой АС на время проведения эксперимента, конфигурируется и удаляется по его окончании.

Для деплоя и параметров атаки (для каждой отдельной атаки) делается свой, заранее настроенный конфигурационный файл (например, -chaoskube-forcekill-template.yaml)

Пример запуска:
`oc process -f CloudAttack/attacks/chaoskube-forcekill-template.yaml -p target_namespaces=ci01234567-server3dm-os4-vector-a-nt -p target_apps=app=vector-review -p kill_interval=1m -p dry_run_flag=--no-dry-run | oc create -f -`

Результат запуска:
`deployment.apps/chaoskube created`

Завершение теста:
`oc delete deployment.apps/chaoskube`

# Windows
Инструменты для Windows систем портабельные и установки как таковой не требуют (можно сказать, что установка заключается в копировании файлов на целевую машину).
Администраторы стендов, как правило, не имеют прав администратора АС и могут проводить установку только через ЗНО на ИНФРу (администраторов Windows).
С администраторами ИНФРы удалось договориться об автоматизации установки этих инструментов через winrm. Существующие фреймворки ДТ копируют их перед выполнением испытаний и удаляют по окончании.

Для Windows систем используются следующие инструменты:

**CPUburn** – для утилизации CPU на Windows-серверах.
Позволяет использовать 100% всех доступных ядер, нагружая процессор интенсивными операциями, что полезно при стресс-тестировании.
Утилизация 100% CPU:

`$proc = Start-Job -ScriptBlock{c:\path\to\cpuburn.exe}; sleep 600; Stop-Job $proc`

Более подробное описание CPUburn можно найти по [ссылке](https://github.com/patrickmn/cpuburn)

**clumsy** – для ухудшения сетевых соединений на Windows-серверах,
clumsy захватывает сетевые пакеты, вызывая их запаздывание, повреждение или потерю, в зависимости от целей. Инструмент для отслеживания ошибок, связанных с неработающей сетью, или для оценки работы приложений при плохом соединении.
Потеря 7% пакетов:

`Start-Job -ScriptBlock{c:\path\to\clumsy.exe --filter "tcp.DstPort != 3389 and tcp.DstPort != 389" --drop on --drop-chance 7.0}; sleep 60; Stop-Process -Name "clumsy"`

Более подробное описание clumsy можно найти по [ссылке](https://github.com/jagt/clumsy/)

**diskspd** – для утилизации дисковой подсистемы на Windows-серверах.
Нагружает дисковую подсистему и измеряет её производительность.
Утилизация 100% пропускной способности дисковой подсистемы:

`diskspd -c2G -w50 -d60 <logdir>/diskspd.test`

Утилита запускает несколько потоков, каждый из которых осуществляет IO операции с таргетом. Таргетом может быть файл, номер физического диска или буква тома.
Если тестировать операции записи, необходимо в качестве таргета указывать какой-нибудь временный файл, иначе данные на диске/томе будут повреждены!

Более подробное описание diskspd можно найти по [ссылке](https://github.com/microsoft/diskspd)

**ozy_test_win** – тест для загрузки ОЗУ до 100% (требуется: NET Framework 3.5 или выше).

После запуска утилиты с аргументами "-a 1 100 600 -launcher", в течение 10 секунд будет заполнено около 10 GB RAM. После заполнения всей памяти начнёт заполняться выделяемая память (до 100%).
В дальнейшем процессы сторонних приложений могут завершиться с ошибками, новые приложения не будут открываться, любые запущенные процессы будут висеть в ожидании выделяемой памяти.
Для завершения теста вручную (win + r, открыть cmd):
`taskkill /IM ozy_test.exe /F /T`

Желательно провести
`taskkill /IM explorer.exe /F`

и его повторный запуск:
`start explorer.exe`

Более подробное описание ozy_test_win можно найти по [ссылке](https://github.com/Aleksandr7xXx/ozy_test_win)
